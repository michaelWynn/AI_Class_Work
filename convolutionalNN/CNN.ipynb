{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "(train_samples, train_labels), (test_samples, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This the code processes MNIST images:\n",
    "train_samples = train_samples.reshape(train_samples.shape [0], 28, 28, 1)\n",
    "test_samples = test_samples.reshape(test_samples.shape [0], 28, 28, 1)\n",
    "train_samples = train_samples.astype('float32')\n",
    "test_samples = test_samples.astype('float32')\n",
    "train_samples = train_samples/255\n",
    "test_samples = test_samples/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_train_labels = np_utils.to_categorical(train_labels, 10)\n",
    "c_test_labels = np_utils.to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet = Sequential()\n",
    "convnet.add(Convolution2D(32, 4, 4, activation='relu', input_shape=(28,28,1)))\n",
    "convnet.add(MaxPooling2D(pool_size=(2,2)))\n",
    "convnet.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "convnet.add(MaxPooling2D(pool_size=(1,1)))\n",
    "convnet.add(Dropout(0.3))\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 11s 4ms/step - loss: 0.0899 - accuracy: 0.1060\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0897 - accuracy: 0.1449\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0895 - accuracy: 0.1944\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0892 - accuracy: 0.2252\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0889 - accuracy: 0.2385\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0886 - accuracy: 0.2501\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0882 - accuracy: 0.2564\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0876 - accuracy: 0.2615\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0869 - accuracy: 0.2685\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0859 - accuracy: 0.2751\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0847 - accuracy: 0.2794\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0830 - accuracy: 0.2902\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0814 - accuracy: 0.3087\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0795 - accuracy: 0.3330\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0777 - accuracy: 0.3560\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0763 - accuracy: 0.3706\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0749 - accuracy: 0.3874\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0736 - accuracy: 0.4016\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0721 - accuracy: 0.4226\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0704 - accuracy: 0.4424\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0657 - accuracy: 0.5253\n",
      "\n",
      "accuracy: 52.53%\n",
      "[[0.05353702 0.01974431 0.04661818 ... 0.40827286 0.03583995 0.18584026]\n",
      " [0.04313925 0.22193323 0.11033303 ... 0.01784411 0.10854936 0.01985122]\n",
      " [0.01460586 0.7575498  0.01948297 ... 0.01814711 0.04748943 0.01319407]\n",
      " ...\n",
      " [0.02537766 0.15675141 0.05013942 ... 0.28265867 0.07186951 0.13288532]\n",
      " [0.03689282 0.1383177  0.04037926 ... 0.28281924 0.05262472 0.1165407 ]\n",
      " [0.3182688  0.00648198 0.1907753  ... 0.02505818 0.0624075  0.03204801]]\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "convnet.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
    "convnet.fit(train_samples, c_train_labels, batch_size=32, epochs=20, verbose=1)\n",
    "metrics = convnet.evaluate(test_samples, c_test_labels, verbose=1)\n",
    "print()\n",
    "print(\"%s: %.2f%%\" % (convnet.metrics_names[1], metrics[1]*100))\n",
    "predictions = convnet.predict(test_samples)\n",
    "print(predictions)\n",
    "print(predictions.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
